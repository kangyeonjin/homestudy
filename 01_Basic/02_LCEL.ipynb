{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH01-Basic\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH01-Basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_teddynote.messages import stream_response  # 스트리밍 출력\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# template 정의\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "# prompt_template\n",
    "\n",
    "# prompt 생성\n",
    "prompt = prompt_template.format(country=\"대한민국\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 일정한 규칙이나 패턴을 학습하는 과정입니다. 이 학습은 주로 머신러닝 알고리즘을 통해 이루어지며, 데이터를 통해 모델이 스스로 패턴을 발견하고 예측을 수행할 수 있도록 학습됩니다.\\n\\n모델은 입력 데이터와 이에 대한 정답(라벨)을 받아서 예측을 수행하고, 이 예측과 실제 정답을 비교하여 오차를 계산합니다. 그리고 이 오차를 최소화하는 방향으로 모델의 가중치와 편향을 조정하면서 점차적으로 정확도를 향상시키는 과정을 반복하면서 모델이 학습됩니다.\\n\\n이러한 학습 원리를 통해 인공지능 모델은 복잡한 데이터 패턴을 학습하고, 새로운 데이터에 대한 예측을 수행할 수 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 313, 'prompt_tokens': 33, 'total_tokens': 346, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-1ed641b9-72fe-49af-ad40-875ab4676ec2-0', usage_metadata={'input_tokens': 33, 'output_tokens': 313, 'total_tokens': 346, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=2048,\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "# prompt 를 PromptTemplate 객체로 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "# input 딕셔너리에 주제를 '인공지능 모델의 학습 원리'으로 설정합니다.\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}\n",
    "\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 데이터를 입력으로 받아들이고, 이 데이터를 기반으로 모델이 내재된 알고리즘에 따라 학습하는 과정을 말합니다. 이 과정은 크게 입력층, 은닉층, 출력층으로 구성된 인공신경망을 사용하여 이루어집니다.\n",
      "\n",
      "먼저, 모델은 입력층에서 데이터를 받아들입니다. 이 데이터는 각각의 특성을 나타내는 값들로 구성되어 있습니다. 그 다음, 입력층에서 받은 데이터는 은닉층을 거쳐 출력층으로 전달됩니다. 은닉층은 모델이 데이터 간의 패턴이나 관계를 학습하는 과정을 담당합니다.\n",
      "\n",
      "모델은 학습 데이터를 이용하여 입력과 출력 간의 관계를 학습하고, 이를 토대로 새로운 데이터에 대한 예측을 수행합니다. 학습 과정에서 모델은 손실 함수를 사용하여 예측 값과 실제 값의 차이를 계산하고, 이를 최소화하기 위해 가중치와 편향을 조정합니다.\n",
      "\n",
      "이렇게 학습된 모델은 새로운 데이터를 입력으로 받았을 때, 이를 기반으로 정확한 예측을 수행할 수 있습니다. 이러한 방식으로 인공지능 모델은 데이터를 기반으로 스스로 패턴을 학습하고, 문제를 해결하는 능력을 갖춥니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream(input)\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 패턴과 규칙을 찾아내는 과정입니다. 모델은 입력 데이터와 정답 레이블을 이용하여 학습을 진행하며, 이를 통해 데이터 간의 관계를 이해하고 예측을 수행할 수 있습니다. 학습 과정은 입력 데이터를 모델에 주고 예측 결과를 확인하면서 가중치를 조정하고 오차를 최소화하는 방향으로 모델을 개선해나갑니다. 이렇게 반복적인 학습 과정을 통해 모델은 입력 데이터에 대한 패턴을 파악하고 새로운 데이터에 대해 예측을 수행할 수 있게 됩니다."
     ]
    }
   ],
   "source": [
    "#출력파서\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# 프롬프트, 모델, 출력 파서를 연결하여 처리 체인을 구성합니다.\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# chain 객체의 invoke 메서드를 사용하여 input을 전달합니다.\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}\n",
    "chain.invoke(input)\n",
    "\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream(input)\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 패턴을 학습하고 결과를 예측하는 과정입니다. 모델은 입력된 데이터와 정답 데이터를 이용해 학습을 하며, 학습을 통해 입력 데이터의 패턴을 인식하고 정확한 결과를 예측할 수 있게 됩니다.\n",
      "\n",
      "모델은 입력 데이터를 받아 가중치와 편향을 조절하면서 학습을 진행하고, 이를 통해 입력 데이터와 정답 데이터 간의 관계를 찾아내게 됩니다. 학습이 끝나면 모델은 새로운 데이터를 입력으로 받아 정확한 결과를 예측할 수 있습니다.\n",
      "\n",
      "이렇게 학습된 모델은 실제 데이터에 대한 예측을 수행하거나 새로운 문제를 해결하는 데 사용될 수 있습니다. 따라서 인공지능 모델의 학습 원리는 데이터를 기반으로 패턴을 찾아내어 문제를 해결하는 과정이라고 할 수 있습니다."
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}\n",
    "\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream(input)\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:\n",
      "  1. Good evening, may I have a table for two, please?\n",
      "  2. Could I see the menu, please?\n",
      "  3. I’ll have the steak, medium rare, and a side of mashed potatoes.\n",
      "  4. Could you recommend a good wine to go with the steak?\n",
      "  5. Thank you, that would be all for now.\n",
      "\n",
      "- 한글 해석:\n",
      "  1. 안녕하세요, 두 명이서 앉을 수 있는 테이블 있나요?\n",
      "  2. 메뉴판 좀 볼 수 있을까요?\n",
      "  3. 스테이크 한 개랑, 매시드 포테이토 사이드로 주세요. 스테이크는 미디엄 레어로요.\n",
      "  4. 스테이크에 어울리는 좋은 와인 추천해주실 수 있나요?\n",
      "  5. 감사합니다, 일단 이것으로 주문할게요.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "당신은 영어를 가르치는 10년차 영어 선생님입니다. 주어진 상황에 맞는 영어 회화를 작성해 주세요.\n",
    "양식은 [FORMAT]을 참고하여 작성해 주세요.\n",
    "\n",
    "#상황:\n",
    "{question}\n",
    "\n",
    "#FORMAT:\n",
    "- 영어 회화:\n",
    "- 한글 해석:\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿을 이용하여 프롬프트를 생성합니다.\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# ChatOpenAI 챗모델을 초기화합니다.\n",
    "model = ChatOpenAI(model_name=\"gpt-4-turbo\")\n",
    "\n",
    "# 문자열 출력 파서를 초기화합니다.\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 체인을 구성합니다.\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
    "print(chain.invoke({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:\n",
      "  1. Customer: \"Hello, I'd like to have a table for two, please.\"\n",
      "  2. Waiter: \"Certainly! Right this way. Here's your menu.\"\n",
      "  3. Customer: \"Thank you. Could you give us a couple of minutes to decide?\"\n",
      "  4. Waiter: \"Of course. I'll be back shortly. Let me know if you have any questions.\"\n",
      "  5. Customer: \"Can you recommend something from the menu?\"\n",
      "  6. Waiter: \"Sure, our special today is grilled salmon with a lemon butter sauce. It's very popular.\"\n",
      "  7. Customer: \"That sounds great. We'll have two of those, please.\"\n",
      "  8. Waiter: \"Would you like any drinks to start with?\"\n",
      "  9. Customer: \"Yes, could we have two glasses of white wine?\"\n",
      "  10. Waiter: \"Absolutely, I'll bring those right over.\"\n",
      "\n",
      "- 한글 해석:\n",
      "  1. 손님: \"안녕하세요, 두 명이서 식사할 수 있는 자리로 부탁드려요.\"\n",
      "  2. 웨이터: \"물론이죠! 이쪽으로 오세요. 메뉴판 드릴게요.\"\n",
      "  3. 손님: \"감사합니다. 메뉴를 결정하는 데 조금 시간이 필요할 것 같아요.\"\n",
      "  4. 웨이터: \"알겠습니다. 곧 다시 오겠습니다. 궁금한 것이 있으면 말씀해 주세요.\"\n",
      "  5. 손님: \"메뉴 중에서 추천해 주실 수 있는 게 있나요?\"\n",
      "  6. 웨이터: \"네, 오늘의 특선은 레몬 버터 소스를 곁들인 구운 연어입니다. 매우 인기가 많아요.\"\n",
      "  7. 손님: \"좋아요. 그것 두 개로 주세요.\"\n",
      "  8. 웨이터: \"음료는 먼저 시작하시겠어요?\"\n",
      "  9. 손님: \"네, 화이트 와인 두 잔 주세요.\"\n",
      "  10. 웨이터: \"네, 바로 가져다 드리겠습니다.\""
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"})\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "멀티모달이란 여러 가지 형태의 다양한 미디어를 결합하여 정보를 전달하는 방식을 말합니다. 이는 텍스트, 이미지, 오디오, 비디오 등 다양한 매체를 활용해 사용자에게 풍부한 경험을 제공하며 상호작용을 촉진합니다. 멀티모달은 사용자들이 다양한 감각을 활용해 정보를 이해하고 소통하는데 도움을 줍니다."
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ChatOpenAI 모델을 인스턴스화합니다.\n",
    "model = ChatOpenAI()\n",
    "# 주어진 토픽에 대한 농담을 요청하는 프롬프트 템플릿을 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대하여 3문장으로 설명해줘.\")\n",
    "# 프롬프트와 모델을 연결하여 대화 체인을 생성합니다.\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "# chain.stream 메서드를 사용하여 '멀티모달' 토픽에 대한 스트림을 생성하고 반복합니다.\n",
    "for token in chain.stream({\"topic\": \"멀티모달\"}):\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ChatGPT는 오픈AI에서 개발된 인공지능 챗봇으로, 자연어 처리 기술을 사용하여 대화를 수행합니다. 사용자와의 대화를 통해 정보 제공, 질문에 대한 답변, 일상적인 대화 등 다양한 기능을 제공합니다. 머신 러닝 알고리즘을 기반으로 하여 점차적으로 대화 능력을 향상시키고 있습니다.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 객체의 invoke 메서드를 호출하고, 'ChatGPT'라는 주제로 딕셔너리를 전달합니다.\n",
    "chain.invoke({\"topic\": \"ChatGPT\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ChatGPT는 인공지능 기술을 활용하여 자연어로 대화하는 챗봇 서비스이다. 사용자들은 ChatGPT를 통해 다양한 주제에 대한 정보나 대화를 나눌 수 있다. ChatGPT는 사용자의 질문에 정확하고 자연스러운 답변을 제공하여 상호작용을 향상시키는 데 도움을 준다.',\n",
       " 'Instagram은 사진과 동영상을 공유하고 다른 사용자들과 소통할 수 있는 소셜 미디어 플랫폼이다. 사용자들은 해시태그를 통해 관심사를 공유하고 팔로워들과 소통하며 자신의 일상을 공유할 수 있다. 또한 인플루언서들이 상품 홍보나 브랜드 홍보를 위해 활발하게 활용하는 플랫폼으로 유명하다.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `chain.batch`는 여러 개의 딕셔너리를 포함하는 리스트를 인자로 받아, \n",
    "# 각 딕셔너리에 있는 `topic` 키의 값을 사용하여 일괄 처리를 수행\n",
    "\n",
    "# 주어진 토픽 리스트를 batch 처리하는 함수 호출\n",
    "chain.batch([{\"topic\": \"ChatGPT\"}, {\"topic\": \"Instagram\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ChatGPT는 OpenAI에서 개발한 자연어 처리 기술로, 대화형 인공지능 챗봇을 구축하는 데 사용됩니다. 이 모델은 대화를 통해 사용자와 상호작용하고 다양한 주제에 대해 대화를 이끌어나갈 수 있습니다. ChatGPT는 자연스러운 대화를 제공하여 사용자들에게 혁신적이고 효과적인 대화 경험을 제공합니다.',\n",
       " '인스타그램은 사진과 동영상을 공유하는 소셜 미디어 플랫폼으로, 전 세계적으로 많은 이용자들이 활발하게 이용하고 있는 서비스이다. 사용자들은 팔로워들과 소통하며 일상을 공유하고, 다양한 콘텐츠를 즐기며 소통할 수 있다. 또한 인스타그램은 광고를 통해 비즈니스 활동을 하는 사용자들에게도 유용한 플랫폼으로 자리매김하고 있다.',\n",
       " '멀티모달은 여러 가지 다양한 형태의 정보나 자료를 결합하여 제공하는 시스템이다. 이는 텍스트, 이미지, 음성, 영상 등 다양한 형태의 데이터를 통합적으로 제공하여 사용자에게 다양한 경험을 제공한다. 멀티모달은 정보의 이해와 전달을 보다 효율적으로 도와주며, 사용자들에게 더 나은 경험을 제공할 수 있다.',\n",
       " '프로그래밍은 컴퓨터에게 명령을 내리는 작업이다. 이를 통해 컴퓨터는 원하는 작업을 수행하고 원하는 결과를 출력한다. 프로그래밍은 문제 해결과 창의적인 사고를 요구하는 활동이다.',\n",
       " '머신러닝은 컴퓨터가 데이터를 학습하고 패턴을 발견하여 예측이나 결정을 내릴 수 있도록 하는 인공지능 분야이다. 이를 위해 통계학과 컴퓨터 과학이 결합되어 다양한 알고리즘이 개발되었고, 이를 통해 더 나은 의사결정과 예측이 가능해졌다. 머신러닝은 이미지 인식, 자연어 처리, 추천 시스템 등 다양한 분야에서 활발히 활용되고 있다.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch(\n",
    "    [\n",
    "        {\"topic\": \"ChatGPT\"},\n",
    "        {\"topic\": \"Instagram\"},\n",
    "        {\"topic\": \"멀티모달\"},\n",
    "        {\"topic\": \"프로그래밍\"},\n",
    "        {\"topic\": \"머신러닝\"},\n",
    "    ],\n",
    "    config={\"max_concurrency\": 3},  #동시에 처리할수잇는 최대 작업수\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
